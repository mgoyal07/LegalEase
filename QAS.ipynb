{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!apt install libpoppler-cpp-dev\n",
        "!pip install pdftotext\n",
        "!pip install transformers\n",
        "!python -m nltk.downloader punkt\n",
        "!pip install sentencepiece\n",
        "\n",
        "import pdftotext\n",
        "import re\n",
        "\n",
        "import itertools\n",
        "from nltk import sent_tokenize\n",
        "import torch\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "from transformers import AutoModelForQuestionAnswering\n",
        "\n",
        "import random"
      ],
      "metadata": {
        "id": "amh8HeC9Csxh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c499839-10e5-4540-f154-ef5b34dd5503"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libpoppler-cpp-dev is already the newest version (22.02.0-2ubuntu0.4).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Requirement already satisfied: pdftotext in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TextProcessingAndContextCreation :\n",
        "\n",
        "    @classmethod\n",
        "    def get_context_chunks(cls, file_name) :\n",
        "\n",
        "        raw_text = cls._get_raw_text_from_pdf(file_name)\n",
        "\n",
        "        first_page_number = cls._get_the_first_page_number(raw_text)\n",
        "        if first_page_number == -1 :\n",
        "            print(\"Error encountered\")\n",
        "            return []\n",
        "\n",
        "        raw_text = raw_text[first_page_number:]\n",
        "\n",
        "        cls._remove_header_of_first_page(raw_text)\n",
        "\n",
        "        cls._delete_footer_notes(raw_text)\n",
        "\n",
        "        cls._remove_captial_words(raw_text)\n",
        "\n",
        "        text = cls._join_all_pages(raw_text)\n",
        "\n",
        "        text = cls._split_the_text_on_bold_points(text)\n",
        "\n",
        "        cls._filter_and_get_plain_text(text)\n",
        "\n",
        "        contexts =  cls._get_the_contexts(text)\n",
        "        return contexts\n",
        "\n",
        "    @classmethod\n",
        "    def _get_raw_text_from_pdf(cls, file_name) :\n",
        "\n",
        "        with open(file_name, \"rb\") as f :\n",
        "            pdf_text = pdftotext.PDF(f)\n",
        "\n",
        "        raw_text = []\n",
        "        for i in pdf_text :\n",
        "            raw_text.append(str(i))\n",
        "        return raw_text\n",
        "\n",
        "    @classmethod\n",
        "    def _get_the_first_page_number(cls, raw_text) :\n",
        "\n",
        "        index = -1\n",
        "        try :\n",
        "            index = raw_text[0].split().index('ACT,')\n",
        "        except :\n",
        "            year_regex = r\"[0-9]{4}\"\n",
        "            for i in range(len(raw_text[0].split())) :\n",
        "                if (re.match(year_regex, raw_text[0].split()[i])) is not None :\n",
        "                    index = i\n",
        "                    break\n",
        "\n",
        "        if index == -1 :\n",
        "            return -1\n",
        "\n",
        "        match_text_page_zero = \" \".join(raw_text[0].split()[:index + 1])\n",
        "        for i in range(1, len(raw_text)) :\n",
        "            page_match_text = \" \".join(raw_text[i].split()[:index + 1])\n",
        "            if match_text_page_zero == page_match_text :\n",
        "                return i\n",
        "\n",
        "        return -1\n",
        "\n",
        "    @classmethod\n",
        "    def _remove_header_of_first_page(cls, raw_text) :\n",
        "\n",
        "        temp = re.match(r\"(.|\\n)*?\\[.*\\]\", raw_text[0])\n",
        "        raw_text[0] = raw_text[0][temp.end():]\n",
        "\n",
        "    @classmethod\n",
        "    def _delete_footer_notes(cls, raw_text) :\n",
        "\n",
        "        footer_regex = r\"1\\..*\"\n",
        "        for i in range(len(raw_text)) :\n",
        "            temp = raw_text[i].split('\\n')[:-2]\n",
        "            for j in range(len(temp) - 1, -1, -1) :\n",
        "                if re.match(footer_regex, temp[j]) is not None :\n",
        "                    break\n",
        "            if j != 0 :\n",
        "                temp = temp[:j]\n",
        "            raw_text[i] = \"\\n\".join(temp)\n",
        "\n",
        "    @classmethod\n",
        "    def _remove_captial_words(cls, raw_text) :\n",
        "\n",
        "        for i in range(len(raw_text)) :\n",
        "            raw_text[i] = raw_text[i].split('\\n')\n",
        "            raw_text[i] = list(filter(lambda x: not (x.isupper()), raw_text[i]))\n",
        "            raw_text[i] = \"\\n\".join(raw_text[i])\n",
        "\n",
        "    @classmethod\n",
        "    def _join_all_pages(cls, raw_text) :\n",
        "\n",
        "        concatenated_text = []\n",
        "        for i in raw_text :\n",
        "            concatenated_text.append(i)\n",
        "        concatenated_text = \"\\n\".join(concatenated_text)\n",
        "        return concatenated_text\n",
        "\n",
        "    @classmethod\n",
        "    def _split_the_text_on_bold_points(cls, text) :\n",
        "\n",
        "        split_regex = r\"[0-9]+[A-Z]*\\.[^\\n]\"\n",
        "        split_text = re.split(split_regex, text)\n",
        "        return split_text\n",
        "\n",
        "    @classmethod\n",
        "    def _filter_and_get_plain_text(cls, text) :\n",
        "\n",
        "        for i in range(len(text)) :\n",
        "            text[i] = re.sub(r\"(“|”|’)\", \"\\\"\", text[i])\n",
        "            text[i] = re.sub(r\"\\n\", \" \", text[i])\n",
        "            text[i] = re.sub(r\" +\", \" \", text[i])\n",
        "            text[i] = re.sub(r\"––\", \"- \", text[i])\n",
        "            text[i] = re.sub(r\"—\", \"- \", text[i])\n",
        "\n",
        "    @classmethod\n",
        "    def _get_the_contexts(cls, text) :\n",
        "\n",
        "        contexts = []\n",
        "        for i in range(len(text)) :\n",
        "            if (len(text[i].split()) < 20) :\n",
        "                continue\n",
        "            elif (len(text[i].split()) >= 20 and len(text[i].split()) <= 350) :\n",
        "                contexts.append(text[i])\n",
        "            else :\n",
        "                temp = cls._get_contexts_greater_than_max_size(text[i])\n",
        "                for i in temp :\n",
        "                    contexts.append(\" \".join(i))\n",
        "\n",
        "        # return contexts\n",
        "        return contexts\n",
        "\n",
        "    @classmethod\n",
        "    def _get_contexts_greater_than_max_size(cls, text) :\n",
        "\n",
        "        ROMAN_NUMERALS = ['i', 'ii', 'iii', 'iv', 'v', 'vi', 'vii', 'viii', 'ix', 'x', \\\n",
        "                          'xi', 'xii', 'xiii', 'xiv', 'xv', 'xvi', 'xvii', 'xviii', 'xix', 'xx', \\\n",
        "                          'xxi', 'xxii', 'xxiii', 'xxiv', 'xxv', 'xxvi', 'xxvii', 'xxviii', 'xxix', 'xxx' \\\n",
        "                          'xxxi', 'xxxii', 'xxxiii', 'xxxiv', 'xxxv', 'xxxvi', 'xxxvii', 'xxxviii', 'xxxix', 'xl' \\\n",
        "                          'xli', 'xlii', 'xliii', 'xliv', 'xlv', 'xlvi', 'xlvii', 'xlviii', 'xlix', 'l', \\\n",
        "                          'li', 'lii', 'liii', 'liv', 'lv', 'lvi', 'lvii', 'lviii', 'lix', 'lx']\n",
        "\n",
        "        level_wise_regex = [r\"\\([0-9]+\\)\", r\"\\([a-z]{1,2}\\)\", r\"\\((\" + \"|\".join(ROMAN_NUMERALS) + r\")\\)\" , r\"\\([A-Z]\\)\"]\n",
        "        punctuations = \",-.:;\"\n",
        "        end_markers = \".;\"\n",
        "        current_index = 0\n",
        "        regex_match_flag = 0\n",
        "        max_context_length = 0\n",
        "\n",
        "        contexts = []\n",
        "        text = text.split()\n",
        "\n",
        "        while (current_index < len(text)) :\n",
        "\n",
        "            regex_match_flag = 0\n",
        "            max_context_length = min(current_index + 350, len(text))\n",
        "            context = text[current_index:max_context_length]\n",
        "            if max_context_length == len(text) :\n",
        "                contexts.append(context)\n",
        "                current_index += len(context)\n",
        "            else :\n",
        "                i = len(context) - 1\n",
        "                while i > (len(context) // 2) :\n",
        "\n",
        "                    # Try matching one of the regular expression\n",
        "                    if (re.match(level_wise_regex[0], context[i]) is not None) or \\\n",
        "                        (re.match(level_wise_regex[1], context[i]) is not None) or \\\n",
        "                        (re.match(level_wise_regex[2], context[i]) is not None) or \\\n",
        "                        (re.match(level_wise_regex[3], context[i]) is not None) :\n",
        "                        # The previous word should end with punctuation\n",
        "                        if i != 0 and context[i-1][-1] in punctuations :\n",
        "                            context = context[:i]\n",
        "                            contexts.append(context)\n",
        "                            current_index += i\n",
        "                            regex_match_flag = 1\n",
        "                            break\n",
        "                    i -= 1\n",
        "\n",
        "                if not regex_match_flag :\n",
        "                    i = len(context) - 1\n",
        "                    while (i > 0) :\n",
        "                        if context[i][-1] in end_markers :\n",
        "                            context = context[:i + 1]\n",
        "                            contexts.append(context)\n",
        "                            current_index += (i + 1)\n",
        "                            break\n",
        "                        i -= 1\n",
        "\n",
        "            if len(contexts[-1]) < 20 :\n",
        "                del contexts[-1]\n",
        "\n",
        "        return contexts\n"
      ],
      "metadata": {
        "id": "kv16MN2yCxVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "from nltk import sent_tokenize\n",
        "\n",
        "import torch\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "PIPELINE_SETTINGS = {\n",
        "    #\"model\": \"valhalla/t5-base-qg-hl\",\n",
        "    \"model\": \"mrm8488/t5-base-finetuned-question-generation-ap\",    # Question Generation model\n",
        "    \"ans_model\": [\"valhalla/t5-base-qa-qg-hl\"]                      # List of Ans extraction models. We can add more than one.\n",
        "}"
      ],
      "metadata": {
        "id": "5XLapvqrDRl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QGPipeline:\n",
        "\n",
        "    def __init__(self, pipeline_settings: dict = PIPELINE_SETTINGS, use_cuda: bool = True) :\n",
        "\n",
        "        self.model = AutoModelForSeq2SeqLM.from_pretrained(pipeline_settings['model'])\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(pipeline_settings['model'], use_fast=False)\n",
        "\n",
        "        self.ans_model = []\n",
        "        self.ans_tokenizer = []\n",
        "        for i in range(len(pipeline_settings['ans_model'])) :\n",
        "            self.ans_model.append(AutoModelForSeq2SeqLM.from_pretrained(pipeline_settings['ans_model'][i]))\n",
        "            self.ans_tokenizer.append(AutoTokenizer.from_pretrained(pipeline_settings['ans_model'][i], use_fast=False))\n",
        "\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() and use_cuda else \"cpu\"\n",
        "        self.model.to(self.device)\n",
        "        for i in range(len(self.ans_model)) :\n",
        "            if self.ans_model[i] is not self.model:\n",
        "                self.ans_model[i].to(self.device)\n",
        "\n",
        "\n",
        "    def __call__(self, text : str):\n",
        "\n",
        "        input_text = \" \".join(text.split())\n",
        "        answers = self._extract_answers(input_text)\n",
        "        if len(answers) == 0:\n",
        "          return []\n",
        "\n",
        "        questions = self._generate_questions(answers, input_text)\n",
        "        question_answers_list = []\n",
        "        for question, answer in zip(questions, answers) :\n",
        "            question_answers_list.append({'question': question, 'answer': answer})\n",
        "        return question_answers_list\n",
        "\n",
        "\n",
        "    def _extract_answers(self, context):\n",
        "\n",
        "        inputs = self._prepare_inputs_for_ans_extraction(context)\n",
        "        inputs = self._tokenize(inputs, padding=True, truncation=True)\n",
        "\n",
        "        answers = []\n",
        "        for i in range(len(self.ans_model)) :\n",
        "            outs = self.ans_model[i].generate(\n",
        "                input_ids=inputs['input_ids'].to(self.device),\n",
        "                attention_mask=inputs['attention_mask'].to(self.device),\n",
        "                max_length=64,\n",
        "            )\n",
        "\n",
        "            dec = [self.ans_tokenizer[i].decode(ids, skip_special_tokens=False) for ids in outs]\n",
        "            decoded_output = [item.split('<sep>') for item in dec]\n",
        "            decoded_output = [i[0] for i in decoded_output]\n",
        "            answers.extend(decoded_output)\n",
        "\n",
        "        for i in range(len(answers)) :\n",
        "            answers[i] = answers[i].replace(\"<pad> \", \"\")\n",
        "        answers = list(set(answers))\n",
        "        return answers\n",
        "\n",
        "\n",
        "    def _prepare_inputs_for_ans_extraction(self, text):\n",
        "\n",
        "        sents = sent_tokenize(text)\n",
        "        inputs = []\n",
        "        for i in range(len(sents)) :\n",
        "            # Append the text 'extract answers' to each sample\n",
        "            source_text = \"extract answers:\"\n",
        "            for j, sent in enumerate(sents):\n",
        "                if i == j:\n",
        "                    sent = \"<hl> %s <hl>\" % sent\n",
        "                source_text = \"%s %s\" % (source_text, sent)\n",
        "                source_text = source_text.strip()\n",
        "\n",
        "            source_text = source_text + \" </s>\"\n",
        "            inputs.append(source_text)\n",
        "\n",
        "        return inputs\n",
        "\n",
        "\n",
        "    def _tokenize(self, inputs, padding=True, truncation=True, add_special_tokens=True, max_length=512):\n",
        "\n",
        "        inputs = self.ans_tokenizer[0].batch_encode_plus(\n",
        "            inputs,\n",
        "            max_length=max_length,\n",
        "            add_special_tokens=add_special_tokens,\n",
        "            truncation=truncation,\n",
        "            padding=\"max_length\" if padding else False,\n",
        "            pad_to_max_length=padding,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return inputs\n",
        "\n",
        "\n",
        "    def _generate_questions(self, answers, context):\n",
        "\n",
        "        questions = []\n",
        "        for answer in answers :\n",
        "            input_text = \"answer: %s  context: %s </s>\" % (answer, context)\n",
        "            inputs = self._tokenize([input_text], padding=True, truncation=True)\n",
        "\n",
        "            outs = self.model.generate(\n",
        "                input_ids=inputs['input_ids'].to(self.device),\n",
        "                attention_mask=inputs['attention_mask'].to(self.device),\n",
        "                max_length=64,\n",
        "                num_beams=4,\n",
        "            )\n",
        "            questions.extend([self.tokenizer.decode(ids, skip_special_tokens=True) for ids in outs])\n",
        "\n",
        "        for i in range(len(questions)) :\n",
        "            questions[i] = questions[i].replace(\"question: \", \"\")\n",
        "        return questions"
      ],
      "metadata": {
        "id": "g35lzS1BDjHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "#-----------Question Answering Module-----------\n",
        "#\n",
        "import torch\n",
        "import numpy as np\n",
        "import transformers\n",
        "from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n",
        "\n",
        "\n",
        "class QA() :\n",
        "\n",
        "    def __init__(self) :\n",
        "        self.model_file = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
        "        self.model = AutoModelForQuestionAnswering.from_pretrained(self.model_file)\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_file)\n",
        "        assert isinstance(self.tokenizer, transformers.PreTrainedTokenizerFast)\n",
        "\n",
        "    def answer_batch(self, questions, contexts, best_size=20, max_answer_length=100) :\n",
        "        max_length = 480    #max length of input(question + context)\n",
        "        doc_stride = 128    #length of overlap between consecutive features of the same example\n",
        "\n",
        "        encodings = self.tokenizer(\n",
        "                questions,\n",
        "                contexts,\n",
        "                truncation=\"only_second\",\n",
        "                max_length=max_length,\n",
        "                stride=doc_stride,\n",
        "                return_overflowing_tokens=True,\n",
        "                return_offsets_mapping=True,\n",
        "                return_attention_mask=True,\n",
        "                padding=\"max_length\"\n",
        "            )\n",
        "\n",
        "        cuda_device = torch.device(\"cuda\")\n",
        "        input_ids = torch.tensor(encodings.input_ids, device=cuda_device)\n",
        "        token_type_ids=torch.tensor(encodings.token_type_ids, device=cuda_device)\n",
        "        attention_mask=torch.tensor(encodings.attention_mask, device=cuda_device)\n",
        "\n",
        "        scores = self.model(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask);\n",
        "        all_start_logits = (scores.start_logits).cpu()\n",
        "        all_end_logits = (scores.end_logits).cpu()\n",
        "\n",
        "        del input_ids\n",
        "        del token_type_ids\n",
        "        del attention_mask\n",
        "        del scores\n",
        "\n",
        "        context_mapping = encodings.pop(\"overflow_to_sample_mapping\")\n",
        "        offset_mappings = encodings.pop(\"offset_mapping\")\n",
        "        context_features = dict()\n",
        "        for i, c in enumerate(context_mapping):\n",
        "            if(c not in context_features.keys()):\n",
        "                context_features[c] = list()\n",
        "            context_features[c].append(i)\n",
        "\n",
        "        best_answers = list()\n",
        "        for c, context in enumerate(contexts):\n",
        "            valid_answers = []\n",
        "            feature_indices = context_features[c]\n",
        "\n",
        "            for feature_index in feature_indices:\n",
        "                start_logits = all_start_logits[feature_index]\n",
        "                end_logits = all_end_logits[feature_index]\n",
        "\n",
        "                offset_mapping = offset_mappings[feature_index]\n",
        "\n",
        "                start_indexes = np.argsort(start_logits.detach().numpy())[-1 : -best_size - 1 : -1].tolist()\n",
        "                end_indexes = np.argsort(end_logits.detach().numpy())[-1 : -best_size - 1 : -1].tolist()\n",
        "                for start_index in start_indexes:\n",
        "                    for end_index in end_indexes:\n",
        "                        if (\n",
        "                            start_index >= len(offset_mapping)\n",
        "                            or end_index >= len(offset_mapping)\n",
        "                            or offset_mapping[start_index] is None\n",
        "                            or offset_mapping[end_index] is None\n",
        "                        ) : continue\n",
        "\n",
        "                        if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
        "                            continue\n",
        "\n",
        "                        start_char = offset_mapping[start_index][0]\n",
        "                        end_char = offset_mapping[end_index][1]\n",
        "                        valid_answers.append(\n",
        "                            {\n",
        "                                \"score\": start_logits[start_index] + end_logits[end_index],\n",
        "                                \"text\": context[start_char: end_char]\n",
        "                            }\n",
        "                        )\n",
        "\n",
        "            if len(valid_answers) > 0:\n",
        "                best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
        "            else:\n",
        "                best_answer = {\"text\": \"<no_answer>\", \"score\": 0.0}\n",
        "            best_answers.append(best_answer)\n",
        "\n",
        "        return best_answers\n",
        "\n",
        "    def answer(self, questions, contexts) :\n",
        "        batch_size = 32\n",
        "        cnt_batches = len(contexts)//batch_size + (1 if len(contexts)%batch_size != 0 else 0)\n",
        "        best_anss = []\n",
        "\n",
        "        self.model.cuda()\n",
        "\n",
        "        for b in range(cnt_batches):\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "            with torch.no_grad() :\n",
        "                result = self.answer_batch(questions[b*batch_size : (b+1)*batch_size], contexts[b*batch_size : (b+1)*batch_size])\n",
        "\n",
        "            best_anss = best_anss + result\n",
        "\n",
        "        answer = sorted(best_anss, key=lambda x: x[\"score\"], reverse=True)[0][\"text\"]\n",
        "        return answer"
      ],
      "metadata": {
        "id": "mYPr9mIxDkQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Main :\n",
        "\n",
        "    qg = QGPipeline()\n",
        "    qa = QA()\n",
        "\n",
        "    @classmethod\n",
        "    def get_contexts_given_the_doc(cls, doc_name) :\n",
        "\n",
        "        contexts = TextProcessingAndContextCreation.get_context_chunks(doc_name)\n",
        "        return contexts\n",
        "\n",
        "\n",
        "    @classmethod\n",
        "    def get_questions_given_the_contexts(cls, context_list) :\n",
        "\n",
        "        generated_questions_and_contexts = []\n",
        "        for context in context_list :\n",
        "            questions = cls.qg(context)\n",
        "            for j in questions :\n",
        "                generated_questions_and_contexts.append([j['question'], context])\n",
        "\n",
        "        return generated_questions_and_contexts\n",
        "\n",
        "\n",
        "    @classmethod\n",
        "    def get_answer_given_the_question_and_context_list(cls, question_context_list) :\n",
        "\n",
        "        answers = []\n",
        "        for i in question_context_list :\n",
        "            answers.append(cls.qa.answer([i[0]], [i[1]]))\n",
        "\n",
        "        return answers\n",
        "\n",
        "\n",
        "    @classmethod\n",
        "    def get_answer_for_single_question_given_context_list(cls, question, context_list) :\n",
        "\n",
        "        repeated_question_list = [question] * len(context_list)\n",
        "        answer = cls.qa.answer(repeated_question_list, context_list)\n",
        "        return answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDrlRTRRD-v4",
        "outputId": "0cdbdb86-f115-41da-dd3a-780833249430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# doc_name = \"/content/The Sexual Harassment of Women at Workplace Act, 2013.pdf\"\n",
        "#doc_name = \"/content/The Aadhaar (Targeted Delivery of Financial and Other Subsidies, Benefits and Services) Act, 2016.pdf\"\n",
        "doc_name = \"/content/The Consumer Protection Act, 2019.pdf\"\n",
        "\n",
        "contexts = Main.get_contexts_given_the_doc(doc_name)\n",
        "contexts = contexts[:5]\n",
        "generated_questions_and_contexts = Main.get_questions_given_the_contexts(contexts)\n",
        "answers = Main.get_answer_given_the_question_and_context_list(generated_questions_and_contexts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGHC1BTFELcP",
        "outputId": "1667112e-25ce-4536-e13d-219326d9e81f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:290: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:290: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, j in zip(generated_questions_and_contexts, answers) :\n",
        "    print(i[0])\n",
        "    print(j)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwjNWexHE8CE",
        "outputId": "d3447235-9308-4336-9d51-b114d8310891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Who enacted the Act in the Seventieth Year of the Republic of India?\n",
            "Parliament\n",
            "An Act to provide for protection of the interests of who?\n",
            "consumers\n",
            "When shall the Consumer Protection Act, 2019 come into force?\n",
            "on such date1\n",
            "What does the Consumer Protection Act apply to?\n",
            "all goods and services\n",
            "What is the exception to the Consumer Protection Act, 2019?\n",
            "Jammu and Kashmir\n",
            "What may this act be called?\n",
            "Consumer Protection Act, 2019\n",
            "What does \"advertisement\" mean?\n",
            "any audio or visual publicity, representation, endorsement or pronouncement made by means of light, sound, smoke, gas, print, electronic media, internet or website\n",
            "Who means a person who knows that the goods are unsafe to the public?\n",
            "trader\n",
            "What does the term \"commercial purpose\" not include use by a person of goods bought and used by him exclusively for?\n",
            "earning his livelihood\n",
            "What does the expression \"buys any goods\" mean?\n",
            "offline or online transactions through electronic means or by teleshopping or direct selling or multi-level marketing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# doc_name = \"/content/The Sexual Harassment of Women at Workplace Act, 2013.pdf\"\n",
        "doc_name = \"/content/The Consumer Protection Act, 2019.pdf\"\n",
        "# question = '''What does \"employee\" mean without the knowledge of the principal employer?'''\n",
        "\n",
        "contexts = Main.get_contexts_given_the_doc(doc_name)\n",
        "contexts = contexts[:5]\n",
        "\n",
        "\n",
        "question = '''What is \"Transitional provision\"?'''\n",
        "#question = '''What does \"advertisement\" mean?''\n",
        "\n",
        "contexts = Main.get_contexts_given_the_doc(doc_name)\n",
        "answer = Main.get_answer_for_single_question_given_context_list(question, contexts)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnV23NclGU1j",
        "outputId": "fa8cd7fd-be44-4d01-a339-e39aeec65a8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "every reference therein to the decree shall be construed as reference to the order made under this Act\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "questions = ['''What is the purpose of the Consumer Protection Act, 2019?''',\n",
        "             '''What is the penalty for false or misleading advertisements?''',\n",
        "             '''What are the rights of a consumer under the act?''',\n",
        "             '''What are the powers and functions of the Central Consumer Protection Authority?''',\n",
        "             '''What is the jurisdiction of the District Consumer Disputes Redressal Commission?''',\n",
        "             '''What is \"Transitional provision\"?'''\n",
        "             ]\n",
        "#question = '''What does \"advertisement\" mean?''\n",
        "\n",
        "contexts = Main.get_contexts_given_the_doc(doc_name)\n",
        "for i in questions:\n",
        "  answer = Main.get_answer_for_single_question_given_context_list(i, contexts)\n",
        "  print(answer)\n",
        "# answer = Main.get_answer_for_single_question_given_context_list(question, contexts)\n",
        "# print(answer)\n"
      ],
      "metadata": {
        "id": "YCUyg4Y-GZEh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e492d0f-8c46-4ca4-8ea1-598075b5f70c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It extends to the whole of India except the State of Jammu and Kashmir\n",
            "imprisonment\n",
            "to call for the records and pass appropriate orders\n",
            "Power of Central Authority to issue directions and penalties against false or misleading advertisements\n",
            "each district of the State\n",
            "every reference therein to the decree shall be construed as reference to the order made under this Act\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rouge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZawhpVA7zX7",
        "outputId": "4d2c79dd-e1b7-4f79-bd48-8dd9bb2fb21e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge import Rouge\n",
        "def calculate_rouge_scores(hypothesis, reference):\n",
        "  assert len(hypothesis) == len(reference), \"Both lists must have the same number of elements.\"\n",
        "  rouge = Rouge()\n",
        "  scores = rouge.get_scores(hypothesis, reference, avg=True)\n",
        "  print(\"ROUGE-1: \", scores['rouge-1'])\n",
        "  print(\"ROUGE-2: \", scores['rouge-2'])\n",
        "  print(\"ROUGE-L: \", scores['rouge-l'])\n",
        "\n",
        "\n",
        "predicted_answers = [\n",
        "    \"It extends to the whole of India except the State of Jammu and Kashmir\",\n",
        "    \"imprisonment\",\n",
        "    \"to call for the records and pass appropriate orders\",\n",
        "    \"Power of Central Authority to issue directions and penalties against false or misleading advertisements\",\n",
        "    \"each district of the State\",\n",
        "    \"every reference therein to the decree shall be construed as reference to the order made under this Act\"\n",
        "]\n",
        "\n",
        "# Ground truth answers\n",
        "correct_answers = [\n",
        "    \"The purpose of the Consumer Protection Act, 2019 is to protect and enforce the rights of consumers, prevent violations of consumer rights, ensure no one engages in unfair trade practices or false/misleading advertisements, and provide mechanisms for redressal of consumer disputes .\",\n",
        "    \"The penalty for false or misleading advertisements can include a penalty up to ten lakh rupees for each instance. For every subsequent contravention, the penalty can extend up to fifty lakh rupees. Additionally, the endorser can be prohibited from endorsing any product for up to one year, which may extend to three years for subsequent contraventions.\",\n",
        "    \"The rights of a consumer under the act include protection against marketing of hazardous goods, being informed about the quality and standard of goods or services, access to a variety of goods or services at competitive prices, the right to be heard, to seek redressal against unfair trade practices, and the right to consumer awareness.\",\n",
        "    \"The Central Consumer Protection Authority has the power to enforce consumer rights, prevent unfair trade practices and false advertisements, conduct investigations, handle consumer complaints, review consumer-related issues, promote consumer rights awareness, and issue safety notices for hazardous goods and services.\",\n",
        "    \"The jurisdiction of the District Consumer Disputes Redressal Commission includes handling complaints where the value of goods or services does not exceed one crore rupees. They can entertain complaints within their local jurisdiction where the opposite party resides or carries on business, or where the cause of action arises.\",\n",
        "    \"The Transitional provision refers to the conditions under which any person appointed as President or as a member of the District Commission before the commencement of this Act will continue to hold office until the completion of their term.\"\n",
        "]\n",
        "\n",
        "# Assuming you have a function to evaluate these based on the earlier provided code\n",
        "calculate_rouge_scores(predicted_answers, correct_answers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wANcdxi96X7m",
        "outputId": "35e273af-edd6-4ac8-d1f8-a56af780252e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE-1:  {'r': 0.09966783947047105, 'p': 0.31587301587301586, 'f': 0.1472591922375079}\n",
            "ROUGE-2:  {'r': 0.012395118230358505, 'p': 0.0625, 'f': 0.01901234473866306}\n",
            "ROUGE-L:  {'r': 0.08982987650750808, 'p': 0.2928571428571428, 'f': 0.13350032698928097}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def normalize_answer(s):\n",
        "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
        "    import re, string\n",
        "    def remove_articles(text):\n",
        "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
        "    def white_space_fix(text):\n",
        "        return ' '.join(text.split())\n",
        "    def remove_punct(text):\n",
        "        exclude = set(string.punctuation)\n",
        "        return ''.join(ch for ch in text if ch not in exclude)\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "    return white_space_fix(remove_articles(remove_punct(lower(s))))\n",
        "\n",
        "def f1_score(prediction, ground_truth):\n",
        "    prediction_tokens = normalize_answer(prediction).split()\n",
        "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
        "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
        "    num_same = sum(common.values())\n",
        "    if num_same == 0:\n",
        "        return 0\n",
        "    precision = 1.0 * num_same / len(prediction_tokens)\n",
        "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "    return f1\n",
        "\n",
        "# List of predicted and ground truth answers\n",
        "predicted_answers = [\n",
        "    \"It extends to the whole of India except the State of Jammu and Kashmir\",\n",
        "    \"imprisonment\",\n",
        "    \"to call for the records and pass appropriate orders\",\n",
        "    \"Power of Central Authority to issue directions and penalties against false or misleading advertisements\",\n",
        "    \"each district of the State\",\n",
        "    \"every reference therein to the decree shall be construed as reference to the order made under this Act\"\n",
        "]\n",
        "\n",
        "correct_answers = [\n",
        "    \"The purpose of the Consumer Protection Act, 2019 is to protect and enforce the rights of consumers, prevent violations of consumer rights, ensure no one engages in unfair trade practices or false/misleading advertisements, and provide mechanisms for redressal of consumer disputes .\",\n",
        "    \"The penalty for false or misleading advertisements can include a penalty up to ten lakh rupees for each instance. For every subsequent contravention, the penalty can extend up to fifty lakh rupees. Additionally, the endorser can be prohibited from endorsing any product for up to one year, which may extend to three years for subsequent contraventions.\",\n",
        "    \"The rights of a consumer under the act include protection against marketing of hazardous goods, being informed about the quality and standard of goods or services, access to a variety of goods or services at competitive prices, the right to be heard, to seek redressal against unfair trade practices, and the right to consumer awareness.\",\n",
        "    \"The Central Consumer Protection Authority has the power to enforce consumer rights, prevent unfair trade practices and false advertisements, conduct investigations, handle consumer complaints, review consumer-related issues, promote consumer rights awareness, and issue safety notices for hazardous goods and services.\",\n",
        "    \"The jurisdiction of the District Consumer Disputes Redressal Commission includes handling complaints where the value of goods or services does not exceed one crore rupees. They can entertain complaints within their local jurisdiction where the opposite party resides or carries on business, or where the cause of action arises.\",\n",
        "    \"The Transitional provision refers to the conditions under which any person appointed as President or as a member of the District Commission before the commencement of this Act will continue to hold office until the completion of their term.\"\n",
        "]\n",
        "\n",
        "# Calculate F1 scores for each pair\n",
        "f1_scores = [f1_score(pred, truth) for pred, truth in zip(predicted_answers, correct_answers)]\n",
        "\n",
        "# Print each F1 score\n",
        "for i, score in enumerate(f1_scores):\n",
        "    print(f\"F1 Score for QA pair {i + 1}: {score:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZAEhEcC7oEi",
        "outputId": "4a509459-23fc-41fc-9f32-0cfafcfbf6f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score for QA pair 1: 0.160\n",
            "F1 Score for QA pair 2: 0.000\n",
            "F1 Score for QA pair 3: 0.071\n",
            "F1 Score for QA pair 4: 0.308\n",
            "F1 Score for QA pair 5: 0.083\n",
            "F1 Score for QA pair 6: 0.245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x96wVT-W-UKi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}